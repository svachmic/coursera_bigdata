{"cells":[{"cell_type":"markdown","source":["# Machine Learning With Big Data\n## by University of California, San Diego\n\n### Week 2\n\n#### 1. Review the scripts:\n\n**doweathclass.py** will create Weather data for predicting if someone will *Play* tennis. The data is hard coded as a list of lists, put into a dataframe and then mapped into an RDD of labeled point vectors. Notice that the categorical variables are recoded as binary indicator variable (eg outlook='sunny' 'overcast' or 'rainy' is replace by 3 variables sunny (1 or 0), overcast (1 or 0), rainy (1 or 0) ).\n\n**doweathclass_naivebayes.py** will execute a Naive Bayes classifier on the RDD of labeled points. There is also some lines of code to get a confusion matrix.\n\n**doweathclass_dectree.py** will execute a Decision Tree classifier on the RDD, and produce a confusion matrix as well.\n\n#### 2. Execute Naive Bayes classification and the NaiveBayes script:\n\nYou should see the confusion matrix printed out and the percent correct.\n\n* What is the approximate percent correct? (save the answer for the quiz)\n* Look at the confusion matrix and write down the numbers for the quiz.\n\n#### 3. Run the decision tree script:\n\nLook at the confusion matrix that is output, save the numbers.\n\nThe decision tree function returns a decision tree object. \n* Review the code. \n* Check out the object. \n* Enter just the object name.\n* Observe how the number of nodes is related to the decision tree."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.regression import LabeledPoint\n\n# outlook, temperature, humidity, windy, play, copied from Weka's data example\nrawdata=[\n  ['sunny'    ,85,85,'FALSE' ,0],\n  ['sunny'    ,80,90,'TRUE'  ,0],\n  ['overcast' ,83,86,'FALSE' ,1],\n  ['rainy'    ,70,96,'FALSE' ,1],\n  ['rainy'    ,68,80,'FALSE' ,1],\n  ['rainy'    ,65,70,'TRUE'  ,0],\n  ['overcast' ,64,65,'TRUE'  ,1],\n  ['sunny'    ,72,95,'FALSE' ,0],\n  ['sunny'    ,69,70,'FALSE' ,1],\n  ['rainy'    ,75,80,'FALSE' ,1],\n  ['sunny'    ,75,70,'TRUE'  ,1],\n  ['overcast' ,72,90,'TRUE'  ,1],\n  ['overcast' ,81,75,'FALSE' ,1],\n  ['rainy'    ,71,91,'TRUE'  ,0]\n]\ndata_df=sqlContext.createDataFrame(rawdata,['outlook','temp','humid','windy','play'])\n\n# transform categoricals into indicator variables\nout2index={'sunny':[1,0,0],'overcast':[0,1,0],'rainy':[0,0,1]}\n\n# make RDD of labeled vectors\ndef newrow(dfrow):\n    outrow = list(out2index.get((dfrow[0])))  # get dictionary entry for outlook\n    outrow.append(dfrow[1])   # temp\n    outrow.append(dfrow[2])   # humidity\n    if dfrow[3]=='TRUE':      # windy\n        outrow.append(1)\n    else:\n        outrow.append(0)\n    return (LabeledPoint(dfrow[4],outrow))\n\ndatax_rdd=data_df.map(newrow)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.mllib.classification import NaiveBayes\n\n# execute model, it can go in a single pass\nmy_nbmodel = NaiveBayes.train(datax_rdd)\n\n# some info on model \nprint my_nbmodel\n# some checks,get some of training data and test it:\ndatax_col=datax_rdd.collect()   # if datax_rdd was big, use sample or take\n\ntrainset_pred =[]\nfor x in datax_col:\n    trainset_pred.append(my_nbmodel.predict(x.features))\n\nprint trainset_pred\n\n# to see class conditionals you might have to install scipy\n# import scipy\n# print 'Class Cond Probabilities, ie p(attr|class= 0 or 1) '\n# print scipy.exp(my_nbmodel.theta)\n# print scipy.exp(my_nbmodel.pi)\n\n# get a confusion matrix\n# the row is the true class label 0 or 1, columns are predicted label\nnb_cf_mat=np.zeros([2,2])  # num of classes\nfor pnt in datax_col:\n    predctn = my_nbmodel.predict(np.array(pnt.features))\n    nb_cf_mat[pnt.label][predctn]+=1\n\ncorrcnt=0\nfor i in range(2):\n    corrcnt+=nb_cf_mat[i][i]\nnb_per_corr=corrcnt/nb_cf_mat.sum()\nprint 'Naive Bayes: Conf.Mat. and Per Corr'\nprint nb_cf_mat\nprint nb_per_corr"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.mllib.tree import DecisionTree\ndt_model = DecisionTree.trainClassifier(datax_rdd,2,{},impurity='entropy',\n          maxDepth=3,maxBins=32, minInstancesPerNode=2)  \n\n# maxDepth and maxBins\n# {} could be categorical feature list,\n# to do regression, have no numclasses,and use trainRegression function\nprint dt_model.toDebugString()\n\n# results in this:\n# DecisionTreeModel classifier of depth 3 with 9 nodes\n#   If (feature 1 <= 0.0)\n#    If (feature 4 <= 80.0)\n#     If (feature 3 <= 68.0)\n#      Predict: 0.0\n#     Else (feature 3 > 68.0)\n#      Predict: 1.0\n#    Else (feature 4 > 80.0)\n#     If (feature 0 <= 0.0)\n#      Predict: 0.0\n#     Else (feature 0 > 0.0)\n#      Predict: 0.0\n#   Else (feature 1 > 0.0)\n#    Predict: 1.0\n\n# notice number of nodes are the predict (leaf nodes) and the ifs\n           \n# some checks, get some of training data and test it:\ndatax_col=datax_rdd.collect()   # if datax_rdd was big, use sample or take\n\n# redo the conf. matrix code (it would be more efficient to pass a model)\ndt_cf_mat=np.zeros([2,2])  # num of classes\nfor pnt in datax_col:\n    predctn = dt_model.predict(np.array(pnt.features))\n    dt_cf_mat[pnt.label][predctn]+=1\ncorrcnt=0\nfor i in range(2): \n    corrcnt+=dt_cf_mat[i][i]\ndt_per_corr=corrcnt/dt_cf_mat.sum()\nprint 'Decision Tree: Conf.Mat. and Per Corr'\nprint dt_cf_mat\nprint dt_per_corr"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Further actions:\n\n#### 6. Let's try adding a useless variable. \n\nIn the **doweathclass.py** script add a new variable that is constant, after the 'play' column, as follows (it is short enough to edit by hand):\n\n```python\nrawdata=[\n  ['sunny'    ,85,85,'FALSE' ,0,1],  \n  ['sunny'    ,80,90,'TRUE'  ,0,1],\n  ['overcast' ,83,86,'FALSE' ,1,1],\n  ['rainy'    ,70,96,'FALSE' ,1,1],\n...etc\n```\n\nNow to process this rawdata list I have to change the rest of code a bit as follows. First change the dataframe creation to include a 'mydummy' field:\n\n```python\ndata_df=sqlContext.createDataFrame(rawdata, ['outlook','temp','humid','windy','play','mydummy']) # <--add field\n```\n\nNext, change the function that creates labeled points. The function should have 1 more line of code (see the 'add this' marked line) that just includes the new column in the labeled point vector.\n\n```python\n#make RDD of labeled vectors\ndef newrow(dfrow):    \n    outrow = list(out2index.get((dfrow[0])))  #get dictionary entry\n    outrow.append(dfrow[1])   #temp    \n    outrow.append(dfrow[2])   #humidity    \n    if dfrow[3]=='TRUE':      #windy        \n        outrow.append(1)    \n    else:        \n        outrow.append(0)    \n    outrow.append(dfrow[5])  # <---- add this     \n    return (LabeledPoint(dfrow[4],outrow))\n```\n\nNow rerun the NaiveBayes and DecisionTree scripts, and observe the impact on the percent correct.\n\n#### 7. Lets add a new test point.\n\nCreate an numpy array with the following values:\n\n```python\n# this for the outlook binary indicator variables, sunny, overcast, rainy\n# temperature = 68\n# humidy = 79\n# windy = 0\n# useless-constant dummy variable = 1\nnewpoint  = np.array([1, 0, 0, 68, 79, 0, 1])\n```\n\nNow run that test point through the NaiveBayes and DecisionTree model using the predict functions.\n\n```python\nmy_nbmodel.predict( ....)\ndt_model.predict( ... )\n```\nYou should see that the NaiveBayes and Decision Tree gave different answers. It is very difficult to say exactly why the answer are different, without recreating the entire algorithm calculations. However, we can do a quick analysis as follows;\n\nPrint the decision tree out and look at how the test point is labeled in that tree. For example, observe which variables are used to get the prediction node for this test point."],"metadata":{}}],"metadata":{"name":"decision_trees","notebookId":3442010556433954},"nbformat":4,"nbformat_minor":0}
